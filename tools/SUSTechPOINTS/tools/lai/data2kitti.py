import json
import os
import math
import numpy as np
import random
import shutil
import csv

random.seed(0)  # å›ºå®šéšæœºç§å­ç¡®ä¿ç»“æœå¯å¤ç°
np.random.seed(0)

# ===== æ–°å¢é›·è¾¾è·¯å¾„ =====
# sourceRadarPath = 'F:/carlaæ•°æ®å¤‡ä»½/rain1_3_4_7_6_8/radar/'
# radarTrainingPath = 'F:/data_carla/vod_carla_1219/radar/training/velodyne/'
# radarTestingPath = 'F:/data_carla/vod_carla_1219/radar/testing/velodyne/'
# ===== æ–°å¢ç»“æŸ =====

label_path = '/workspace/ros2_yolo/tools/SUSTechPOINTS/data/618_date/label'
calibFile = '/workspace/ros2_yolo/tools/SUSTechPOINTS/data/618_date/calib/camera/front.json'
sourceImagePath = '/workspace/ros2_yolo/tools/SUSTechPOINTS/data/618_date/camera/front'
sourceVelodynePath = '/workspace/ros2_yolo/tools/SUSTechPOINTS/data/618_date/lidar'

kittiLabelPath = '/workspace/ros2_yolo/src/mmdetection3d/data/618_data/training/label_2/'
kittiCalibPath = '/workspace/ros2_yolo/src/mmdetection3d/data/618_data/training/calib/'
imageSetsPath = '/workspace/ros2_yolo/src/mmdetection3d/data/618_data/ImageSets/'
trainingPath = '/workspace/ros2_yolo/src/mmdetection3d/data/618_data/training/'
testingPath = '/workspace/ros2_yolo/src/mmdetection3d/data/618_data/testing/'

skipped_frames = []  # ç”¨äºå­˜å‚¨è·³è¿‡çš„å¸§IDåˆ—è¡¨

def is_empty_json(file_path):
    """æ£€æŸ¥JSONæ–‡ä»¶æ˜¯å¦ä¸ºç©ºï¼ˆæ— ç›®æ ‡ï¼‰"""
    if not os.path.exists(file_path):
        print(f"âš ï¸ æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return True
    
    try:
        with open(file_path) as fp:
            jsonContent = json.load(fp)
        return len(jsonContent) == 0
    except json.JSONDecodeError:
        print(f"âŒ JSONè§£æé”™è¯¯: {file_path}")
        return True
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {file_path}, é”™è¯¯: {str(e)}")
        return True

def frame_id_to_num(filename):
    """ä»æ–‡ä»¶åä¸­æå–å¸§å·æ•°å­—"""
    return int(filename.split('.')[0])

def calibLabelFileGen(Path, fname, jsonContent, istrain=True):
    """ç”ŸæˆKITTIæ ¼å¼çš„æ ‡ç­¾å’Œæ ‡å®šæ–‡ä»¶"""
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(Path + "label_2/", exist_ok=True)
    os.makedirs(Path + "calib/", exist_ok=True)
    
    # å¦‚æœæ˜¯è®­ç»ƒé›†ï¼Œå¤„ç†æ ‡ç­¾æ–‡ä»¶
    if istrain:
        label_file_path = os.path.join(Path, "label_2", fname.replace('json', 'txt'))
        
        # å¦‚æœæœ‰æ—§æ–‡ä»¶å­˜åœ¨ï¼Œåˆ é™¤å®ƒ
        if os.path.exists(label_file_path):
            os.remove(label_file_path)
        
        # å¤„ç†æ¯ä¸ªå¯¹è±¡
        print(f"å¤„ç† {fname}ï¼ŒåŒ…å« {len(jsonContent)} ä¸ªç›®æ ‡")
        for i in range(len(jsonContent)):
            content = jsonContent[i]
            psr = content["psr"]
            position = psr["position"]
            scale = psr["scale"]
            rotation = psr["rotation"]
            pointXYZ = np.array([position["x"], position["y"], position["z"], 1]).T 
            camPosition = np.matmul(Tr_velo_to_cam, pointXYZ)
            
            kittiDict = {}
            kittiDict["objectType"] = content["obj_type"]
            kittiDict["truncated"] = "0.0"
            kittiDict["occluded"] = "0"
            kittiDict["alpha"] = "0.0"
            kittiDict["bbox"] = [0.00, 0.00, 50.00, 50.00]
            kittiDict["diamensions"] = [scale['z'], scale['y'], scale['x']]
            kittiDict["location"] = [camPosition[0], camPosition[1] + float(scale["z"])/2 , camPosition[2] ]
            kittiDict["rotation_y"] = -math.pi/2 - rotation["z"]
            
            with open(label_file_path, 'a+') as f:
                for item in kittiDict.values():
                    if isinstance(item, list):
                        for temp in item:
                            f.writelines(str(temp) + " ")
                    else:        
                        f.writelines(str(item)+ " ")
                f.writelines("\n")
    
    # ç”Ÿæˆæ ‡å®šæ–‡ä»¶
    calib_file_path = os.path.join(Path, "calib", fname.replace('json', 'txt'))
    with open(calib_file_path, 'w') as f:
        P2 =  np.array(intrinsic).reshape(3,3)
        P2 = np.insert(P2, 3, values=np.array([0,0,0]), axis=1)
        
        f.writelines("P0: ")
        for num in P2.flatten():
            f.writelines(str(num)+ " ")
        f.writelines("\n")
        
        f.writelines("P1: ")          
        for num in P2.flatten():
            f.writelines(str(num)+ " ")
        f.writelines("\n")
        
        f.writelines("P2: ")
        for num in P2.flatten():
            f.writelines(str(num)+ " ")
        f.writelines("\n")
        
        f.writelines("P3: ")
        for num in P2.flatten():
            f.writelines(str(num)+ " ")
        f.writelines("\n")
        
        f.writelines("R0_rect: ")
        for num in np.eye(3,3).flatten():
            f.writelines(str(num)+ " ")
        f.writelines("\n")
        
        f.writelines("Tr_velo_to_cam: ")
        for temp in Tr_velo_to_cam[:3].flatten():
            f.writelines(str(temp) + " ")
        f.writelines("\n")
        
        f.writelines("Tr_imu_to_velo: ")
        for temp in Tr_velo_to_cam[:3].flatten():
            f.writelines(str(temp) + " ")

def getCalibMatrix():
    """è·å–ç›¸æœºçš„å†…å¤–å‚çŸ©é˜µ"""
    with open(calibFile) as fp:
        calib = json.load(fp)
    return calib["extrinsic"], calib["intrinsic"]

# ä¸»ç¨‹åºå¼€å§‹
extrinsic, intrinsic = getCalibMatrix()
Tr_velo_to_cam = np.array(extrinsic).reshape(4,4)
print("Tr_velo_to_cam Extrinsic: ", Tr_velo_to_cam)

# è·å–æ‰€æœ‰æ ‡ç­¾æ–‡ä»¶å¹¶æŒ‰å¸§å·æ’åº
files = sorted(os.listdir(label_path))
print(f"è·å–åˆ° {len(files)} ä¸ªåŸå§‹æ•°æ®æ–‡ä»¶")

# æŒ‰æ–‡ä»¶åä¸­çš„æ•°å­—è¿›è¡Œæ’åº
files = sorted(files, key=frame_id_to_num)
print("å·²æŒ‰å¸§å·é¡ºåºæ’åºæ–‡ä»¶")

# ====== å…³é”®ä¿®æ”¹ï¼šå…ˆè¿‡æ»¤ç©ºæ ‡ç­¾æ–‡ä»¶ ======
valid_files = []  # å­˜å‚¨å®é™…æœ‰æ•ˆçš„æ–‡ä»¶
for fname in files:
    source_label_path = os.path.join(label_path, fname)
    if not is_empty_json(source_label_path):
        valid_files.append(fname)
    else:
        frame_id = fname.replace(".json", "")
        skipped_frames.append(frame_id)
        print(f"ğŸš« è·³è¿‡ç©ºæ ‡ç­¾å¸§: {frame_id}")

total_num = len(valid_files)  # å®é™…æœ‰æ•ˆæ–‡ä»¶æ•°

# # ====== å…³é”®ä¿®æ”¹ï¼šæŒ‰æœ‰æ•ˆæ–‡ä»¶åˆ’åˆ†æ•°æ®é›† ======
# # è®¡ç®—æ¯ä¸ªåŒºé—´çš„å¤§å°ï¼ˆç¡®ä¿æ¯ä¸ªåŒºé—´éƒ½æœ‰è®­ç»ƒå’Œæµ‹è¯•æ ·æœ¬ï¼‰
# interval_size = 100  # æ¯100å¸§ä¸ºä¸€ä¸ªåŒºé—´
# num_intervals = total_num // interval_size + (1 if total_num % interval_size > 0 else 0)
# print(f"å°†æ•°æ®åˆ’åˆ†ä¸º {num_intervals} ä¸ªåŒºé—´ï¼Œæ¯ä¸ªåŒºé—´ {interval_size} å¸§")

# # è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ¯”ä¾‹è®¾å®š
# train_ratio = 0.8  # æ¯ä¸ªåŒºé—´80%ç”¨äºè®­ç»ƒ

# # å¤„ç†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
# train_indices = []   # è®­ç»ƒé›†æ–‡ä»¶åˆ—è¡¨
# test_indices = []    # æµ‹è¯•é›†æ–‡ä»¶åˆ—è¡¨

# # éå†æ¯ä¸ªåŒºé—´
# for interval in range(num_intervals):
#     start_idx = interval * interval_size
#     end_idx = min((interval + 1) * interval_size, total_num)
#     interval_files = valid_files[start_idx:end_idx]
    
#     if not interval_files:
#         continue
        
#     # è®¡ç®—å½“å‰åŒºé—´çš„è®­ç»ƒé›†å¤§å°
#     interval_train_num = int(len(interval_files) * train_ratio)
    
#     # ç¡®ä¿æ¯ä¸ªåŒºé—´è‡³å°‘æœ‰1ä¸ªè®­ç»ƒæ ·æœ¬å’Œ1ä¸ªæµ‹è¯•æ ·æœ¬
#     if interval_train_num == len(interval_files):
#         interval_train_num = len(interval_files) - 1
#     elif interval_train_num == 0:
#         interval_train_num = 1
    
#     # æŠ½å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†
#     interval_train = interval_files[:interval_train_num]
#     interval_test = interval_files[interval_train_num:]
    
#     train_indices.extend(interval_train)
#     test_indices.extend(interval_test)

# ====== ä¿®æ”¹ï¼šè®­ç»ƒé›†å’Œæµ‹è¯•é›†ä½¿ç”¨ç›¸åŒæ•°æ® ======
train_indices = valid_files[:]  # å¤åˆ¶å…¨éƒ¨æœ‰æ•ˆæ–‡ä»¶ä½œä¸ºè®­ç»ƒé›†
test_indices = valid_files[:]   # å¤åˆ¶å…¨éƒ¨æœ‰æ•ˆæ–‡ä»¶ä½œä¸ºæµ‹è¯•é›†

# å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†æŒ‰å¸§å·æ’åº
train_indices = sorted(train_indices, key=frame_id_to_num)
test_indices = sorted(test_indices, key=frame_id_to_num)

print(f"\n===== æ•°æ®é›†åˆ’åˆ†ç»Ÿè®¡ =====")
print(f"æ€»æ–‡ä»¶æ•°: {total_num} (å·²è¿‡æ»¤ç©ºæ ‡ç­¾)")
print(f"è®­ç»ƒé›†æ–‡ä»¶æ•°: {len(train_indices)}")
print(f"æµ‹è¯•é›†æ–‡ä»¶æ•°: {len(test_indices)}")
print(f"è®­ç»ƒé›†æ¯”ä¾‹: {len(train_indices)/total_num:.2f}")
print(f"æµ‹è¯•é›†æ¯”ä¾‹: {len(test_indices)/total_num:.2f}")

# åˆ›å»ºæ–‡ä»¶åˆ—è¡¨æ—¶ä¿æŒé¡ºåº
def write_ordered_file_list(file_path, file_list):
    """æŒ‰å¸§å·é¡ºåºå†™å…¥æ–‡ä»¶åˆ—è¡¨"""
    # æå–å¸§å·å¹¶æ’åº
    frame_ids = sorted([frame_id_to_num(fname.replace('.json', '')) for fname in file_list])
    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œä¿æŒ6ä½æ•°å­—çš„æ ¼å¼
    ordered_list = [str(frame_id).zfill(6) for frame_id in frame_ids]
    
    with open(file_path, 'w') as f:
        for frame_id in ordered_list:
            f.write(frame_id + '\n')
    
    print(f"å·²å†™å…¥ {len(ordered_list)} ä¸ªæœ‰åºå¸§åˆ° {file_path}")

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
for path in [trainingPath, testingPath]:
    for subdir in ['image_2/', 'velodyne/', 'label_2/', 'calib/']:
        os.makedirs(os.path.join(path, subdir), exist_ok=True)
os.makedirs(imageSetsPath, exist_ok=True)

# ç¡®ä¿é›·è¾¾ç›®å½•å­˜åœ¨
# os.makedirs(radarTrainingPath, exist_ok=True)
# os.makedirs(radarTestingPath, exist_ok=True)

# å¤„ç†è®­ç»ƒé›†
print(f"\n===== å¤„ç†è®­ç»ƒé›† ({len(train_indices)}ä¸ªæ–‡ä»¶) =====")
# åˆ›å»ºæœ‰åºçš„train.txt
train_file_path = os.path.join(imageSetsPath, 'train.txt')
write_ordered_file_list(train_file_path, train_indices)

# å¤„ç†è®­ç»ƒé›†æ–‡ä»¶
for i, fname in enumerate(train_indices):
    if i % 100 == 0:  # æ¯å¤„ç†100ä¸ªæ–‡ä»¶æ‰“å°è¿›åº¦
        print(f"è®­ç»ƒé›†è¿›åº¦: {i+1}/{len(train_indices)}")
        
    source_label_path = os.path.join(label_path, fname)
    
    # å¤„ç†éç©ºæ ‡ç­¾ï¼ˆå·²è¿‡æ»¤ï¼Œæ‰€ä»¥éƒ½æ˜¯éç©ºçš„ï¼‰
    with open(source_label_path) as fp:
        jsonContent = json.load(fp)
    calibLabelFileGen(trainingPath, fname, jsonContent, istrain=True)
    
    # å¤åˆ¶å›¾åƒå’Œç‚¹äº‘
    img_src = os.path.join(sourceImagePath, fname.replace("json", "png"))
    img_dst = os.path.join(trainingPath, 'image_2', fname.replace("json", "png"))
    pc_src = os.path.join(sourceVelodynePath, fname.replace("json", "bin"))
    pc_dst = os.path.join(trainingPath, 'velodyne', fname.replace("json", "bin"))
    
    if os.path.exists(img_src) and os.path.exists(pc_src):
        shutil.copy(img_src, img_dst)
        shutil.copy(pc_src, pc_dst)
    else:
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {img_src} æˆ– {pc_src}")
        
    # å¤åˆ¶é›·è¾¾æ•°æ®åˆ°è®­ç»ƒé›†
    # radar_src = os.path.join(sourceRadarPath, fname.replace("json", "bin"))
    # radar_dst = os.path.join(radarTrainingPath, fname.replace("json", "bin"))
    # if os.path.exists(radar_src):
    #     shutil.copy(radar_src, radar_dst)
    # else:
    #     print(f"é›·è¾¾æ–‡ä»¶ä¸å­˜åœ¨: {radar_src}")

# å¤„ç†æµ‹è¯•é›†
print(f"\n===== å¤„ç†æµ‹è¯•é›† ({len(test_indices)}ä¸ªæ–‡ä»¶) =====")
# åˆ›å»ºæœ‰åºçš„test.txt
test_file_path = os.path.join(imageSetsPath, 'test.txt')
write_ordered_file_list(test_file_path, test_indices)

# å¤„ç†æµ‹è¯•é›†æ–‡ä»¶
for i, fname in enumerate(test_indices):
    if i % 100 == 0:  # æ¯å¤„ç†100ä¸ªæ–‡ä»¶æ‰“å°è¿›åº¦
        print(f"æµ‹è¯•é›†è¿›åº¦: {i+1}/{len(test_indices)}")
        
    source_label_path = os.path.join(label_path, fname)
    
    # å¤„ç†éç©ºæ ‡ç­¾ï¼ˆå·²è¿‡æ»¤ï¼Œæ‰€ä»¥éƒ½æ˜¯éç©ºçš„ï¼‰
    with open(source_label_path) as fp:
        jsonContent = json.load(fp)
    calibLabelFileGen(testingPath, fname, jsonContent, istrain=False)
    
    # å¤åˆ¶å›¾åƒå’Œç‚¹äº‘
    img_src = os.path.join(sourceImagePath, fname.replace("json", "png"))
    img_dst = os.path.join(testingPath, 'image_2', fname.replace("json", "png"))
    pc_src = os.path.join(sourceVelodynePath, fname.replace("json", "bin"))
    pc_dst = os.path.join(testingPath, 'velodyne', fname.replace("json", "bin"))
    
    if os.path.exists(img_src) and os.path.exists(pc_src):
        shutil.copy(img_src, img_dst)
        shutil.copy(pc_src, pc_dst)
    else:
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {img_src} æˆ– {pc_src}")
        
    # å¤åˆ¶é›·è¾¾æ•°æ®åˆ°æµ‹è¯•é›†
    # radar_src = os.path.join(sourceRadarPath, fname.replace("json", "bin"))
    # radar_dst = os.path.join(radarTestingPath, fname.replace("json", "bin"))
    # if os.path.exists(radar_src):
    #     shutil.copy(radar_src, radar_dst)
    # else:
    #     print(f"é›·è¾¾æ–‡ä»¶ä¸å­˜åœ¨: {radar_src}")

# åˆ›å»ºå…¶ä»–æ–‡ä»¶é›†çš„å‰¯æœ¬
fileLists = ["trainval.txt", "val.txt"]
for fileName in fileLists:
    src_path = os.path.join(imageSetsPath, 'train.txt')
    dst_path = os.path.join(imageSetsPath, fileName)
    if os.path.exists(src_path):
        shutil.copy(src_path, dst_path)

# ç»Ÿè®¡å¹¶è¾“å‡ºè·³è¿‡ä¿¡æ¯
skipped_count = len(skipped_frames)
if skipped_count > 0:
    print(f"\nğŸš« æ€»å…±è·³è¿‡äº† {skipped_count} å¸§ç©ºæ ‡ç­¾æ•°æ®")
    
    # ä¿å­˜è·³è¿‡çš„å¸§IDåˆ°CSV
    csv_path = os.path.join(imageSetsPath, 'skipped_frames.csv')
    with open(csv_path, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['FrameID'])  # æ ‡é¢˜è¡Œ
        for frame_id in skipped_frames:
            writer.writerow([frame_id])
    print(f"ğŸ“Š è·³è¿‡çš„å¸§åˆ—è¡¨å·²ä¿å­˜åˆ°: {csv_path}")
else:
    print("\nâœ… æœªå‘ç°ç©ºæ ‡ç­¾å¸§")

# æœ€ç»ˆç»Ÿè®¡ï¼ˆè€ƒè™‘è·³è¿‡çš„å¸§ï¼‰
print("\n===== æœ€ç»ˆæ•°æ®é›†ç»Ÿè®¡ =====")
print(f"åŸå§‹æ–‡ä»¶æ•°: {len(files)}")
print(f"æœ‰æ•ˆæ–‡ä»¶æ•°: {total_num} (éç©ºæ ‡ç­¾)")
print(f"è®­ç»ƒé›†æ–‡ä»¶æ•°: {len(train_indices)}")
print(f"æµ‹è¯•é›†æ–‡ä»¶æ•°: {len(test_indices)}")
print(f"è·³è¿‡æ–‡ä»¶æ•°: {len(skipped_frames)}")
print(f"è®­ç»ƒé›†æ¯”ä¾‹: {len(train_indices)/total_num:.2f}")
print(f"æµ‹è¯•é›†æ¯”ä¾‹: {len(test_indices)/total_num:.2f}")
print("æ•°æ®é›†åˆ’åˆ†å®Œæˆ!")
